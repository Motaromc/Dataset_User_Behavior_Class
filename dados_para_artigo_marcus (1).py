# -*- coding: utf-8 -*-
"""dados para artigo - Marcus.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZHhVK-CKkoZbHk_sJejXARdOgm4QHULU

# Avaliação Unidade 1 - Ciência de Dados

Prezad@ alun@!

O projeto da disciplina Ciência de Dados será desenvolvido totalmente neste google colab. Para isso, com base nos conceitos abordados na discplina,  juntamente com o dataset (problema) escolhido por você em nossa primeira atividade, realize a criação de um modelo de aprendizagem de máquina baseado em árvore.

## Funções prontas
"""

import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn import datasets

def calcular_media(valores):
    return sum(valores) / len(valores)

def calcular_moda(valores):
    counts = valores.value_counts()
    moda = counts.index[counts.argmax()]
    return moda

def calcular_media_ponderada(valores, pesos):
    return sum(v * p for v, p in zip(valores, pesos)) / sum(pesos)


def calcular_media_truncada(valores, proporcao_remover):
    valores_ordenados = sorted(valores)
    n_remover = int(len(valores) * proporcao_remover)
    valores_truncados = valores_ordenados[n_remover:len(valores) - n_remover]
    return sum(valores_truncados) / len(valores_truncados)


def calcular_mediana(valores):
    valores_ordenados = sorted(valores)
    n = len(valores)
    meio = n // 2
    if n % 2 == 0:
        return (valores_ordenados[meio - 1] + valores_ordenados[meio]) / 2
    else:
        return valores_ordenados[meio]

def encontrar_outliers(valores, ajuste=1.1): #ajuste 1.1, 1.2
    # Ordenar os valores
    valores_ordenados = sorted(valores)

    # Encontrar Q1 (25º percentil) e Q3 (75º percentil)
    q1 = calcular_mediana(valores_ordenados[:len(valores_ordenados) // 2])
    q3 = calcular_mediana(valores_ordenados[len(valores_ordenados) // 2:])

    # Calcular IQR (Intervalo entre Quartis)
    iqr = q3 - q1

    # Definir limites para outliers
    limite_inferior = q1 - ajuste * iqr
    limite_superior = q3 + ajuste * iqr

    # Encontrar os outliers
    outliers = [v for v in valores if v < limite_inferior or v > limite_superior]
    return outliers



# Função para calcular a variância
def calcular_variancia(dados, media):
    return sum((x - media) ** 2 for x in dados) / len(dados)

# Função para calcular o desvio padrão
def calcular_desvio_padrao(variancia):
    return variancia ** 0.5

# Professor, faltou o senhor colocar aqui os cálculos para desvios e Percentil.

# Função para calcular os desvios adicionada por mim, Marcus.
def calcular_desvios(valores, media):
    return [x - media for x in valores]

# Função para calcular o percentil adicionada por mim, Marcus.
def calcular_percentil(valores, percentil):
    valores_ordenados = sorted(valores)
    indice = int((percentil / 100) * len(valores_ordenados))
    return valores_ordenados[max(0, min(indice, len(valores_ordenados) -1))]

# PS: Essas funções vieram do slide: Idéias Básicas,Motivações e Aplicações (Parte 2)

# Função para calcular a correlação de Pearson
def calcular_correlacao(x, y):
    # Calcular a média de x e y
    media_x = calcular_media(x)
    media_y = calcular_media(y)

    # Calcular a variância de x e y
    variancia_x = calcular_variancia(x, media_x)
    variancia_y = calcular_variancia(y, media_y)

    # Calcular o desvio padrão de x e y
    desvio_x = calcular_desvio_padrao(variancia_x)
    desvio_y = calcular_desvio_padrao(variancia_y)

    # Calcular a covariância
    covariancia = sum((x.values[i] - media_x) * (y.values[i] - media_y) for i in range(len(x))) / len(x)

    # Calcular a correlação de Pearson
    return covariancia / (desvio_x * desvio_y)

# Calculando a matriz de correlação entre todos os pares de atributos
def calcular_matriz_correlacao(df):
  atributos = df.columns
  matriz_correlacao = pd.DataFrame(index=atributos, columns=atributos)
  for i in range(len(atributos)):
      for j in range(i, len(atributos)):
          atributo_x = atributos[i]
          atributo_y = atributos[j]

          # Calculando a correlação entre os atributos
          correlacao = calcular_correlacao(df[atributo_x], df[atributo_y])

          # Preenchendo a matriz de correlação
          matriz_correlacao.loc[atributo_x, atributo_y] = correlacao
          matriz_correlacao.loc[atributo_y, atributo_x] = correlacao  # Matriz é simétrica

  # retorna a matriz de correlação
  return matriz_correlacao

def plot_matriz_correlacao(matriz_correlacao):
  # Visualizando a matriz de correlação com um heatmap
  plt.figure(figsize=(8, 6))
  sns.heatmap(matriz_correlacao.astype(float), annot=True, cmap='coolwarm', vmin=-1, vmax=1)
  plt.xticks(fontsize=12)
  plt.yticks(fontsize=12)
  plt.title('Matriz de Correlação')
  plt.show()

def plt_matriz_disperscao(df):
  # Gráfico de dispersão (scatter plot) entre todas as combinações de atributos
  atributos = df.columns

  # Criando a matriz de gráficos de dispersão usando pairplot do Seaborn
  sns.pairplot(df)
  plt.suptitle('Gráficos de Dispersão entre Atributos', y=1.02)  # Título para o gráfico
  plt.show()

def plt_hist(dados, bins=5):
    # Criando o histograma
    plt.hist(dados, bins, edgecolor='black')  # bins define o número de intervalos

    # Adicionando título e rótulos dos eixos
    plt.title('Histograma de Dados Exemplo')
    plt.xlabel('Valores')
    plt.ylabel('Frequência')

    # Exibindo o histograma
    plt.show()

"""## Funções desenvolvidas por você"""

#aqui você deve disponibilizar todas as funções criadas por você que buscam

"""## Carregamento do dataset"""

#ler arquivo csv
df = pd.read_csv('/content/user_behavior_dataset.csv',index_col=0)

# Cópia do original para usar depois.
df_original = df.copy()

df

"""## Questões

Utilizando as "Funções prontas" e as "Questões desenvolvidas por você", juntamente com os demais conceitos aprendizados em sala, responda as questão a seguir:

### Descrição do dataset

Questão 1 - Faça um resumo com até 200 palavras sobre o contexto do problema que seu dataset representa, utilizando a descrição fornecida pelo prório repositório como base.

R: O meu dataset apresenta a classificação de usuários de aparelhos eletrônicos em diferentes classes, a partir de vários fatores como: Tempo de uso, uso dos dados, consumo de bateria e número de aplicativos instalados.

### Tipos de dados

Questão 2 - Descreva o tipo de cada um dos atributos existentes no seu dataset.

R:
User_ID

Tipo: Numérico
Descrição: Identificação única para cada usuário.

Device Model
Tipo: Categórico
Descrição: Modelo do dispositivo usado pelo usuário.

Operating System
Tipo: Categórico
Descrição: Sistema operacional do dispositivo.

App Usage Time (min/day)
Tipo: Numérico
Descrição: Tempo de uso de aplicativos, em minutos por dia.

Screen On Time (hours/day)
Tipo: Numérico
Descrição: Tempo em que a tela ficou ligada, em horas por dia.

Battery Drain (mAh/day)
Tipo: Numérico
Descrição: Consumo de bateria, em miliampere-hora por dia.

Number of Apps Installed
Tipo: Numérico
Descrição: Quantidade total de aplicativos instalados no dispositivo.

Data Usage (MB/day)
Tipo: Numérico
Descrição: Uso de dados móveis ou Wi-Fi, em megabytes por dia.

Age
Tipo: Numérico
Descrição: Idade do usuário.

Gender
Tipo: Categórico
Descrição: Gênero do usuário.

User Behavior Class
Tipo: Categórico
Descrição: Classe de comportamento do usuário, definida por um rótulo numérico.

### Cálculos de estimativas de localização

Questão 3 - Tomando como base as estimativas de localização estudadas em sala, desenvolva um código que realize estes cálculos para todas as variáveis possíveis de seu dataset. Ao final, faça um análise estatística descritiva em um único parágrafo indicando seus principais achados.

Obs: Utilize: Moda, Média, Média ponderada, Média truncada, Mediana e Outlier;

Obs: Justifique o não uso de determinada estimativa à uma feature específica de seu dataset.
"""

# Estimativas para a coluna App Usage
print("Estimativas para a coluna App Usage:")

media_App_Usage = calcular_media(df['App Usage Time (min/day)'])
print(f"Média: {media_App_Usage}")

media_ponderada_App_Usage = calcular_media_ponderada(df['App Usage Time (min/day)'], df.index)
print(f"Média Ponderada: {media_ponderada_App_Usage}")

media_truncada_App_Usage = calcular_media_truncada(df['App Usage Time (min/day)'], 0.1)
print(f"Média Truncada: {media_truncada_App_Usage}")

mediana_App_Usage = calcular_mediana(df['App Usage Time (min/day)'])
print(f"Mediana: {mediana_App_Usage}")

outliers_App_Usage = encontrar_outliers(df['App Usage Time (min/day)'])
print(f"Outliers: {outliers_App_Usage}")

moda_App_Usage = calcular_moda(df['App Usage Time (min/day)'])
print(f"Moda: {moda_App_Usage}")


# Estimativas para a coluna Screen On Time
print("\nEstimativas para a coluna Screen On Time:")

media_Screen_On_Time = calcular_media(df['Screen On Time (hours/day)'])
print(f"Média: {media_Screen_On_Time}")

media_ponderada_Screen_On_Time = calcular_media_ponderada(df['Screen On Time (hours/day)'], df.index)
print(f"Média Ponderada: {media_ponderada_Screen_On_Time}")

media_truncada_Screen_On_Time = calcular_media_truncada(df['Screen On Time (hours/day)'], 0.1)
print(f"Média Truncada: {media_truncada_Screen_On_Time}")

mediana_Screen_On_Time = calcular_mediana(df['Screen On Time (hours/day)'])
print(f"Mediana: {mediana_Screen_On_Time}")

outliers_Screen_On_Time = encontrar_outliers(df['Screen On Time (hours/day)'])
print(f"Outliers: {outliers_Screen_On_Time}")

moda_Screen_On_Time = calcular_moda(df['Screen On Time (hours/day)'])
print(f"Moda: {moda_Screen_On_Time}")


# Estimativas para a coluna Battery Drain
print("\nEstimativas para a coluna Battery Drain:")

media_Battery_Drain = calcular_media(df['Battery Drain (mAh/day)'])
print(f"Média: {media_Battery_Drain}")

media_ponderada_Battery_Drain = calcular_media_ponderada(df['Battery Drain (mAh/day)'], df.index)
print(f"Média Ponderada: {media_ponderada_Battery_Drain}")

media_truncada_Battery_Drain = calcular_media_truncada(df['Battery Drain (mAh/day)'], 0.1)
print(f"Média Truncada: {media_truncada_Battery_Drain}")

mediana_Battery_Drain = calcular_mediana(df['Battery Drain (mAh/day)'])
print(f"Mediana: {mediana_Battery_Drain}")

outliers_Battery_Drain = encontrar_outliers(df['Battery Drain (mAh/day)'])
print(f"Outliers: {outliers_Battery_Drain}")

moda_Battery_Drain = calcular_moda(df['Battery Drain (mAh/day)'])
print(f"Moda: {moda_Battery_Drain}")


# Estimativas para a coluna Number of Apps Installed
print("\nEstimativas para a coluna Number of Apps Installed:")

media_Number_Of_Apps_Installed = calcular_media(df['Number of Apps Installed'])
print(f"Média: {media_Number_Of_Apps_Installed}")

media_ponderada_Number_Of_Apps_Installed = calcular_media_ponderada(df['Number of Apps Installed'], df.index)
print(f"Média Ponderada: {media_ponderada_Number_Of_Apps_Installed}")

media_truncada_Number_Of_Apps_Installed = calcular_media_truncada(df['Number of Apps Installed'], 0.1)
print(f"Média Truncada: {media_truncada_Number_Of_Apps_Installed}")

mediana_Number_Of_Apps_Installed= calcular_mediana(df['Number of Apps Installed'])
print(f"Mediana: {mediana_Number_Of_Apps_Installed}")

outliers_Number_Of_Apps_Installed = encontrar_outliers(df['Number of Apps Installed'])
print(f"Outliers: {outliers_Number_Of_Apps_Installed}")

moda_Number_Of_Apps_Installed = calcular_moda(df['Number of Apps Installed'])
print(f"Moda: {moda_Number_Of_Apps_Installed}")


# Estimativas para a coluna Data Usage
print("\nEstimativas para a coluna Data Usage:")

media_Data_Usage = calcular_media(df['Data Usage (MB/day)'])
print(f"Média: {media_Data_Usage}")

media_ponderada_Data_Usage = calcular_media_ponderada(df['Data Usage (MB/day)'], df.index)
print(f"Média Ponderada: {media_ponderada_Data_Usage}")

media_truncada_Data_Usage = calcular_media_truncada(df['Data Usage (MB/day)'], 0.1)
print(f"Média Truncada: {media_truncada_Data_Usage}")

mediana_Data_Usage= calcular_mediana(df['Data Usage (MB/day)'])
print(f"Mediana: {mediana_Data_Usage}")

outliers_Data_Usage = encontrar_outliers(df['Data Usage (MB/day)'])
print(f"Outliers: {outliers_Data_Usage}")

moda_Data_Usage = calcular_moda(df['Data Usage (MB/day)'])
print(f"Moda: {moda_Data_Usage}")


# Estimativas para a coluna Age
print("\nEstimativas para a coluna Age:")

media_Age = calcular_media(df['Age'])
print(f"Média: {media_Age}")

media_ponderada_Age = calcular_media_ponderada(df['Age'], df.index)
print(f"Média Ponderada: {media_ponderada_Age}")

media_truncada_Age = calcular_media_truncada(df['Age'], 0.1)
print(f"Média Truncada: {media_truncada_Age}")

mediana_Age= calcular_mediana(df['Age'])
print(f"Mediana: {mediana_Age}")

outliers_Age = encontrar_outliers(df['Age'])
print(f"Outliers: {outliers_Age}")

moda_Age = calcular_moda(df['Age'])
print(f"Moda: {moda_Age}")


# Estimativas para a coluna User Behavior Class
print("\nEstimativas para a coluna User Behavior Class:")

media_User_Behavior_Class = calcular_media(df['User Behavior Class'])
print(f"Média: {media_User_Behavior_Class}")

media_ponderada_User_Behavior_Class = calcular_media_ponderada(df['User Behavior Class'], df.index)
print(f"Média Ponderada: {media_ponderada_User_Behavior_Class}")

media_truncada_User_Behavior_Class = calcular_media_truncada(df['User Behavior Class'], 0.1)
print(f"Média Truncada: {media_truncada_User_Behavior_Class}")

mediana_User_Behavior_Class= calcular_mediana(df['User Behavior Class'])
print(f"Mediana: {mediana_User_Behavior_Class}")

outliers_User_Behavior_Class = encontrar_outliers(df['User Behavior Class'])
print(f"Outliers: {outliers_User_Behavior_Class}")

moda_User_Behavior_Class = calcular_moda(df['User Behavior Class'])
print(f"Moda: {moda_User_Behavior_Class}")

"""R: A partir das análises de moda, média, mediana, média truncada e ponderada, podemos avaliar os comportamentos e modos de uso de cada usuário. Esses os quais apresentam relativa similaridade em uso, devido ao fato de não apresentarem outliers, com exceção da coluna "Data Usage" o que pode indicar discrepâncias no uso de dados de certos ussuários, provavelmente em decorrência de suas profissões.

### Cálculos de estimativas de variabilidade

Questão 4 - Tomando como base as estimativas de variabilidade estudadas em sala, desenvolva um código que realize estes cálculos para todas as variáveis possíveis de seu dataset. Ao final, faça um análise estatística descritiva em um único parágrafo indicando seus principais achados.

Obs: Utilize: Desvios, Variância, Desvio Padrão e Percentil.

Obs: Justifique o não uso de determinada estimativa à uma feature específica de seu dataset.
"""

# Estimativas para a coluna App Usage
print("Estimativas para a coluna App Usage:")

variancia_App_Usage = calcular_variancia(df['App Usage Time (min/day)'], media_App_Usage)
print(f"Variância: {variancia_App_Usage}")

desvio_App_Usage = calcular_desvio_padrao(variancia_App_Usage)
print(f"Desvio Padrão: {desvio_App_Usage}")

desvios_App_Usage = calcular_desvios(df['App Usage Time (min/day)'], media_App_Usage)
print(f"Desvios: {desvios_App_Usage}")

percentil_App_Usage = calcular_percentil(df['App Usage Time (min/day)'], 80)
print(f"Percentil: {percentil_App_Usage}")


# Estimativas para a coluna Screen On Time
print("\nEstimativas para a coluna Screen On Time:")

variancia_Screen_On_Time = calcular_variancia(df['Screen On Time (hours/day)'], media_Screen_On_Time)
print(f"Variância: {variancia_Screen_On_Time}")

desvio_Screen_On_Time = calcular_desvio_padrao(variancia_Screen_On_Time)
print(f"Desvio Padrão: {desvio_Screen_On_Time}")

desvios_Screen_On_Time = calcular_desvios(df['Screen On Time (hours/day)'], media_Screen_On_Time)
print(f"Desvios: {desvios_Screen_On_Time}")

percentil_Screen_On_Time = calcular_percentil(df['Screen On Time (hours/day)'], 80)
print(f"Percentil: {percentil_Screen_On_Time}")


# Estimativas para a coluna Battery Drain
print("\nEstimativas para a coluna Battery Drain:")

variancia_Battery_Drain = calcular_variancia(df['Battery Drain (mAh/day)'], media_Battery_Drain)
print(f"Variância: {variancia_Battery_Drain}")

desvio_Battery_Drain = calcular_desvio_padrao(variancia_Battery_Drain)
print(f"Desvio Padrão: {desvio_Battery_Drain}")

desvios_Battery_Drain = calcular_desvios(df['Battery Drain (mAh/day)'], media_Battery_Drain)
print(f"Desvios: {desvios_Battery_Drain}")

percentil_Battery_Drain = calcular_percentil(df['Battery Drain (mAh/day)'], 80)
print(f"Percentil: {percentil_Battery_Drain}")


# Estimativas para a coluna Number of Apps Installed
print("\nEstimativas para a coluna Number of Apps Installed:")

variancia_Number_Of_Apps_Installed = calcular_variancia(df['Number of Apps Installed'], media_Number_Of_Apps_Installed)
print(f"Variância: {variancia_Number_Of_Apps_Installed}")

desvio_Number_Of_Apps_Installed = calcular_desvio_padrao(variancia_Number_Of_Apps_Installed)
print(f"Desvio Padrão: {desvio_Number_Of_Apps_Installed}")

desvios_Number_Of_Apps_Installed = calcular_desvios(df['Number of Apps Installed'], media_Number_Of_Apps_Installed)
print(f"Desvios: {desvios_Number_Of_Apps_Installed}")

percentil_Number_Of_Apps_Installed = calcular_percentil(df['Number of Apps Installed'], 80)
print(f"Percentil: {percentil_Number_Of_Apps_Installed}")


# Estimativas para a coluna Data Usage
print("\nEstimativas para a coluna Data Usage:")

variancia_Data_Usage = calcular_variancia(df['Data Usage (MB/day)'], media_Data_Usage)
print(f"Variância: {variancia_Data_Usage}")

desvio_Data_Usage = calcular_desvio_padrao(variancia_Data_Usage)
print(f"Desvio Padrão: {desvio_Data_Usage}")

desvios_Data_Usage = calcular_desvios(df['Data Usage (MB/day)'], media_Data_Usage)
print(f"Desvios: {desvios_Data_Usage}")

percentil_Data_Usage = calcular_percentil(df['Data Usage (MB/day)'], 80)
print(f"Percentil: {percentil_Data_Usage}")


# Estimativas para a coluna Age
print("\nEstimativas para a coluna Age:")

variancia_Age = calcular_variancia(df['Age'], media_Age)
print(f"Variância: {variancia_Age}")

desvio_Age = calcular_desvio_padrao(variancia_Age)
print(f"Desvio Padrão: {desvio_Age}")

desvios_Age = calcular_desvios(df['Age'], media_Age)
print(f"Desvios: {desvios_Age}")

percentil_Age = calcular_percentil(df['Age'], 80)
print(f"Percentil: {percentil_Age}")


# Estimativas para a coluna User Behavior Class
print("\nEstimativas para a coluna User Behavior Class:")

variancia_User_Behavior_Class = calcular_variancia(df['User Behavior Class'], media_User_Behavior_Class)
print(f"Variância: {variancia_User_Behavior_Class}")

desvio_User_Behavior_Class = calcular_desvio_padrao(variancia_User_Behavior_Class)
print(f"Desvio Padrão: {desvio_User_Behavior_Class}")

desvios_User_Behavior_Class = calcular_desvios(df['User Behavior Class'], media_User_Behavior_Class)
print(f"Desvios: {desvios_User_Behavior_Class}")

percentil_User_Behavior_Class = calcular_percentil(df['User Behavior Class'], 80)
print(f"Percentil: {percentil_User_Behavior_Class}")

"""R: Como pode ser visto acima, Esses resultados destacam alta variabilidade nos padrões de uso, com distribuições assimétricas em algumas métricas. Como por exemplo no consumo de bateria, visto que muitos usuários apresentam diferentes necessidades e utilizam a ferramenta de acordo com elas.

### Distribuição de dados

Questão 5 - Tomando como base cada um dos atributos de seu dataset, indique e crie gráficos de histogramas que demonstrem se seus atributos apresentam distribuição:
- Uniforme;
- Simétrica;
- Assimétrica;
- Dissimétrica.
"""

def plt_hist(dados, nome_coluna, bins=10):
    # Criando o histograma
    plt.hist(dados, bins, edgecolor='black')  # bins define o número de intervalos

    # Adicionando título e rótulos dos eixos
    plt.title(nome_coluna)
    plt.xlabel('Valores')
    plt.ylabel('Usuários')

    # Exibindo o histograma
    plt.show()

plt_hist(df['App Usage Time (min/day)'], 'App Usage Time (min/day)')
plt_hist(df['Screen On Time (hours/day)'], 'Screen On Time (hours/day)')
plt_hist(df['Battery Drain (mAh/day)'], 'Battery Drain (mAh/day)')
plt_hist(df['Number of Apps Installed'], 'Number of Apps Installed')
plt_hist(df['Data Usage (MB/day)'], 'Data Usage (MB/day)')
plt_hist(df['Age'], 'Age')
plt_hist(df['User Behavior Class'], 'User Behavior Class')

"""R: User_ID: Uniforme.
App Usage Time (min/day): Assimétrico positivo.
Screen On Time (hours/day): Assimétrico positivo).
Battery Drain (mAh/day): Assimétrico positivo.
Number of Apps Installed: Assimétrico negativo.
Data Usage (MB/day): Assimétrico positivo.
Age: Simétrico.
User Behavior Class: Dissimétrico.

### Correlações

Questão 6 - Realize os cálculos de correlações entre todos os atributos de seu dataset, em seguida, resposta as perguntas relacionadas a esta questão:
"""

# Estimativas de correlação para a coluna App Usage
print("Estimativas de correlação para a coluna App Usage:")

correlacao_App_Usage = calcular_correlacao(df['App Usage Time (min/day)'], df['Screen On Time (hours/day)'])
print(f"Correlação entre App Usage e Screen On time: {correlacao_App_Usage}")

correlacao_App_Usage = calcular_correlacao(df['App Usage Time (min/day)'], df['Battery Drain (mAh/day)'])
print(f"Correlação entre App Usage e Battery Drain: {correlacao_App_Usage}")

correlacao_App_Usage = calcular_correlacao(df['App Usage Time (min/day)'], df['Number of Apps Installed'])
print(f"Correlação entre App Usage e Number of Apps Installed: {correlacao_App_Usage}")

correlacao_App_Usage = calcular_correlacao(df['App Usage Time (min/day)'], df['Data Usage (MB/day)'])
print(f"Correlação entre App Usage e Data Usage: {correlacao_App_Usage}")

correlacao_App_Usage = calcular_correlacao(df['App Usage Time (min/day)'], df['Age'])
print(f"Correlação entre App Usage e Age: {correlacao_App_Usage}")

correlacao_App_Usage = calcular_correlacao(df['App Usage Time (min/day)'], df['User Behavior Class'])
print(f"Correlação entre App Usage e User Behaviour Class: {correlacao_App_Usage}")


# Estimativas de correlação para a coluna Screen on time
print("\nEstimativas de correlação para a coluna Screen on time:")

correlacao_Screen_On_Time = calcular_correlacao(df['Screen On Time (hours/day)'], df['App Usage Time (min/day)'])
print(f"Correlação entre Screen On Time e App Usage: {correlacao_Screen_On_Time}")

correlacao_Screen_On_Time = calcular_correlacao(df['Screen On Time (hours/day)'], df['Battery Drain (mAh/day)'])
print(f"Correlação entre Screen On Time e Battery Drain: {correlacao_Screen_On_Time}")

correlacao_Screen_On_Time = calcular_correlacao(df['Screen On Time (hours/day)'], df['Number of Apps Installed'])
print(f"Correlação entre Screen On Time e Number of Apps Installed: {correlacao_Screen_On_Time}")

correlacao_Screen_On_Time = calcular_correlacao(df['Screen On Time (hours/day)'], df['Data Usage (MB/day)'])
print(f"Correlação entre Screen On Time e Data Usage: {correlacao_Screen_On_Time}")

correlacao_Screen_On_Time = calcular_correlacao(df['Screen On Time (hours/day)'], df['Age'])
print(f"Correlação entre Screen On time e Age: {correlacao_Screen_On_Time}")

correlacao_Screen_On_Time = calcular_correlacao(df['Screen On Time (hours/day)'], df['User Behavior Class'])
print(f"Correlação entre Screen On Time e User Behaviour Class: {correlacao_Screen_On_Time}")


# Estimativas de correlação para a coluna Battery Drain
print("\nEstimativas de correlação para a coluna Battery Drain:")

correlacao_Battery_Drain = calcular_correlacao(df['Battery Drain (mAh/day)'], df['App Usage Time (min/day)'])
print(f"Correlação entre Battery Drain e App Usage: {correlacao_Battery_Drain}")

correlacao_Battery_Drain = calcular_correlacao(df['Battery Drain (mAh/day)'], df['Screen On Time (hours/day)'])
print(f"Correlação entre Battery Drain e Screen On Time: {correlacao_Battery_Drain}")

correlacao_Battery_Drain = calcular_correlacao(df['Battery Drain (mAh/day)'], df['Number of Apps Installed'])
print(f"Correlação entre Battery Drain e Number of Apps Installed: {correlacao_Battery_Drain}")

correlacao_Battery_Drain = calcular_correlacao(df['Battery Drain (mAh/day)'], df['Data Usage (MB/day)'])
print(f"Correlação entre Battery Drain e Data Usage: {correlacao_Battery_Drain}")

correlacao_Battery_Drain = calcular_correlacao(df['Battery Drain (mAh/day)'], df['Age'])
print(f"Correlação entre Battery Drain e Age: {correlacao_Battery_Drain}")

correlacao_Battery_Drain = calcular_correlacao(df['Battery Drain (mAh/day)'], df['User Behavior Class'])
print(f"Correlação entre Battery Drain e User Behaviour Class: {correlacao_Battery_Drain}")


# Estimativas de correlação para a coluna Number of Apps Installed
print("\nEstimativas de correlação para a coluna Number of Apps Installed:")

correlacao_Number_Of_Apps_Installed = calcular_correlacao(df['Number of Apps Installed'], df['App Usage Time (min/day)'])
print(f"Correlação entre Number of Apps Installed e App Usage: {correlacao_Number_Of_Apps_Installed}")

correlacao_Number_Of_Apps_Installed = calcular_correlacao(df['Number of Apps Installed'], df['Screen On Time (hours/day)'])
print(f"Correlação entre Number of Apps Installed e Screen On Time: {correlacao_Number_Of_Apps_Installed}")

correlacao_Number_Of_Apps_Installed = calcular_correlacao(df['Number of Apps Installed'], df['Battery Drain (mAh/day)'])
print(f"Correlação entre Number of Apps Installed e Battery Drain: {correlacao_Number_Of_Apps_Installed}")

correlacao_Number_Of_Apps_Installed = calcular_correlacao(df['Number of Apps Installed'], df['Data Usage (MB/day)'])
print(f"Correlação entre Number of Apps Installed e Data Usage: {correlacao_Number_Of_Apps_Installed}")

correlacao_Number_Of_Apps_Installed = calcular_correlacao(df['Number of Apps Installed'], df['Age'])
print(f"Correlação entre Number of Apps Installed e Age: {correlacao_Number_Of_Apps_Installed}")

correlacao_Number_Of_Apps_Installed = calcular_correlacao(df['Number of Apps Installed'], df['User Behavior Class'])
print(f"Correlação entre Number of Apps Installed e User Behaviour Class: {correlacao_Number_Of_Apps_Installed}")


# Estimativas de correlação para a coluna Data Usage
print("\nEstimativas de correlação para a coluna Data Usage:")

correlacao_Data_Usage = calcular_correlacao(df['Data Usage (MB/day)'], df['App Usage Time (min/day)'])
print(f"Correlação entre Data Usage e App Usage: {correlacao_Data_Usage}")

correlacao_Data_Usage = calcular_correlacao(df['Data Usage (MB/day)'], df['Screen On Time (hours/day)'])
print(f"Correlação entre Data Usage e Screen On Time: {correlacao_Data_Usage}")

correlacao_Data_Usage = calcular_correlacao(df['Data Usage (MB/day)'], df['Battery Drain (mAh/day)'])
print(f"Correlação entre Data Usage e Battery Drain: {correlacao_Data_Usage}")

correlacao_Data_Usage = calcular_correlacao(df['Data Usage (MB/day)'], df['Number of Apps Installed'])
print(f"Correlação entre Data Usage e Number of Apps Installed: {correlacao_Data_Usage}")

correlacao_Data_Usage = calcular_correlacao(df['Data Usage (MB/day)'], df['Age'])
print(f"Correlação entre Data Usage e Age: {correlacao_Data_Usage}")

correlacao_Data_Usage = calcular_correlacao(df['Data Usage (MB/day)'], df['User Behavior Class'])
print(f"Correlação entre Data Usage e User Behaviour Class: {correlacao_Data_Usage}")


# Estimativas de correlação para a coluna Age
print("\nEstimativas de correlação para a coluna Age:")

correlacao_Age = calcular_correlacao(df['Age'], df['App Usage Time (min/day)'])
print(f"Correlação entre Age e App Usage: {correlacao_Age}")

correlacao_Age = calcular_correlacao(df['Age'], df['Screen On Time (hours/day)'])
print(f"Correlação entre Age e Screen On Time: {correlacao_Age}")

correlacao_Age = calcular_correlacao(df['Age'], df['Battery Drain (mAh/day)'])
print(f"Correlação entre Age e Battery Drain: {correlacao_Age}")

correlacao_Age = calcular_correlacao(df['Age'], df['Number of Apps Installed'])
print(f"Correlação entre Age e Number of Apps Installed: {correlacao_Age}")

correlacao_Age = calcular_correlacao(df['Age'], df['Data Usage (MB/day)'])
print(f"Correlação entre Age e Data Usage: {correlacao_Age}")

correlacao_Age = calcular_correlacao(df['Age'], df['User Behavior Class'])
print(f"Correlação entre Age e User Behaviour Class: {correlacao_Age}")


# Estimativas de correlação para a coluna User Behavior Class
print("\nEstimativas de correlação para a coluna User Behavior Class:")

correlacao_User_Behavior_Class = calcular_correlacao(df['User Behavior Class'], df['App Usage Time (min/day)'])
print(f"Correlação entre User Behavior Class e App Usage: {correlacao_User_Behavior_Class}")

correlacao_User_Behavior_Class = calcular_correlacao(df['User Behavior Class'], df['Screen On Time (hours/day)'])
print(f"Correlação entre User Behavior Class e Screen On Time: {correlacao_User_Behavior_Class}")

correlacao_User_Behavior_Class = calcular_correlacao(df['User Behavior Class'], df['Battery Drain (mAh/day)'])
print(f"Correlação entre User Behavior Class e Battery Drain: {correlacao_User_Behavior_Class}")

correlacao_User_Behavior_Class = calcular_correlacao(df['User Behavior Class'], df['Number of Apps Installed'])
print(f"Correlação entre User Behavior Class e Number of Apps Installed: {correlacao_User_Behavior_Class}")

correlacao_User_Behavior_Class = calcular_correlacao(df['User Behavior Class'], df['Data Usage (MB/day)'])
print(f"Correlação entre User Behavior Class e Data Usage: {correlacao_User_Behavior_Class}")

correlacao_User_Behavior_Class = calcular_correlacao(df['User Behavior Class'], df['Age'])
print(f"Correlação entre User Behavior Class e Age: {correlacao_User_Behavior_Class}")

# Assuming 'df' is your DataFrame
plt.figure(figsize=(8, 6))  # Adjust figure size if needed

# Create the scatter plot
plt.scatter(df['App Usage Time (min/day)'], df['Battery Drain (mAh/day)'])

# Add labels and title
plt.xlabel('App Usage Time (min/day)')
plt.ylabel('Battery Drain (mAh/day)')
plt.title('Correlação entre Battery Drain e App Usage Time')

# Show the plot
plt.show()

"""Questão 6.1 - Qual atributo apresenta maior correlação com o atributo objetivo?

R: A coluna Number of Apps Installed com 0.98

Questão 6.2 - Qual atributo apresenta menor correlação com o atributo objetivo?

R: A coluna Age com -0.0005

Questão 6.3 - Seu dataset apresenta atributos com correlações perfeita entre sí?

R: Infelizmente não, mas algumas variáveis se aproximam bastante como o exemplo de Number of apps Installed e User Behavior

Questões 6.4 - Existem atributos que poderiam ser retirados de seu dataset, visando diminuir a dimensionalidade dele sem que houvesse a diminuição de performance do modelo? Se sim, qual/quais? Se não, justifique!

R: Sim, como por exemplo: O atributo Age, por ser o que apresenta menor correlação com o atributo principal, o User behavior Class, indicando que a idade não é um fator crucial para o modo que as pessoas utilizam os aparelhos

### Transformações de atributos

Durante a disciplina estudamos como converter um atributo categório -> numérico e numérico -> categórico. Agora é sua vez!

Questão 7 - Realize a transformação de pelo menos dois atributos categóricos -> numéricos ou dois atributos numéricos em categóricos em seu dataset. Em seguida discuta em um parágrafo se houve ou não mudança na performance do modelo (árvore de decisão) após a mudança.

R: Essencialmente, as alterações que eu fiz acima não diferem muito do que já estava feito anteriormente. Por exemplo, transformar o atributo categórico gênero em um atríbuto numérico binário continua nos fornecendo a mesma informação, porém em forma de bits. Por outro lado, utilizar somente atributos numéricos facilitou o manuseio do dataset ao transforma-lo em uma árvore de decisão como visto logo abaixo.

## Modelo de aprendizagem de máquina
"""

# Importação de bibliotecas necessárias
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.tree import DecisionTreeRegressor
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from sklearn.metrics import mean_squared_error

def convert_gender(df):
  for i in df.index:
    if df.at[i,'Gender'] == 'Male':
      df.at[i,'Gender'] = 1
    elif df.at[i,'Gender'] == 'Female':
      df.at[i,'Gender'] = 0
    elif df.at[i,'Gender'] == 'Other':
      df.at[i,'Gender'] = 2
  return df

df = convert_gender(df)

def convert_Operating_System(df):
  for i in df.index:
    if df.at[i,'Operating System'] == 'Android':
      df.at[i,'Operating System'] = 0
    elif df.at[i,'Operating System'] == 'iOS':
      df.at[i,'Operating System'] = 1
  return df

def convert_Device_Model(df):
  for i in df.index:
    if df.at[i,'Device Model'] == 'Google Pixel 5':
      df.at[i,'Device Model'] = 0
    elif df.at[i,'Device Model'] == 'OnePlus 9':
      df.at[i,'Device Model'] = 1
    elif df.at[i,'Device Model'] == 'Samsung Galaxy S21':
      df.at[i,'Device Model'] = 2
    elif df.at[i,'Device Model'] == 'Xiaomi Mi 11':
      df.at[i,'Device Model'] = 3
    elif df.at[i,'Device Model'] == 'iPhone 12':
      df.at[i,'Device Model'] = 4
  return df

df_original = convert_gender(df)

df_original = convert_Device_Model(df)

df_original = convert_Operating_System(df)

def convert_object_to_numeric(df):

    for col in df.select_dtypes(include=['object']).columns:
        try:
            df[col] = pd.to_numeric(df[col])
        except ValueError:
            print(f"Impossível converter '{col}' para numeric.")
    return df

df = convert_object_to_numeric(df)

df_original

#separando variaveis X e Y
X = df.drop('User Behavior Class', axis=1)
y = df['User Behavior Class']

X

y

# Dividindo o dataset em treinamento (70%) e teste (30%)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Criando o modelo de árvore de decisão
model = DecisionTreeClassifier(random_state=42)


# Treinando o modelo com os dados de treinamento
model.fit(X_train, y_train)

# Realizando previsões nos dados de teste
y_pred = model.predict(X_test)

# Calculando a matriz de confusão
cm = confusion_matrix(y_test, y_pred)

# Exibindo a matriz de confusão como um gráfico
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=df['User Behavior Class'].unique())
disp.plot(cmap="Blues")

# Calculando o erro quadrático médio
mse = mean_squared_error(y_test, y_pred)

# Exibindo o resultado
print(f"Erro Quadrático Médio (MSE): {mse}")

plt.figure(figsize=(12, 8))
plot_tree(
    model,
    feature_names=X.columns,
    class_names=[str(c) for c in y.unique()],
    filled=True,
    label='none',  # Remove os rótulos dos nós
    impurity=False,  # Remove a informação de impureza
#    proportion=False  # Remove proporções
)
plt.show()

import tensorflow as tf
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import mean_squared_error, accuracy_score, log_loss
from sklearn.tree import DecisionTreeClassifier
import matplotlib.pyplot as plt

# Parâmetros globais
RANDOM_STATE = 42
TEST_SIZE = 0.3
EPOCHS = 10

# Pré-processamento
label_encoder = LabelEncoder()
y = label_encoder.fit_transform(df['User Behavior Class'])
X = df.drop('User Behavior Class', axis=1)

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE
)

# Modelo de Rede Neural
def build_nn(input_shape, output_shape):
    model = tf.keras.models.Sequential([
        tf.keras.layers.Dense(128, activation='relu', input_shape=(input_shape,)),
        tf.keras.layers.Dense(64, activation='relu'),
        tf.keras.layers.Dense(output_shape, activation='softmax')
    ])
    model.compile(optimizer='adam',
                  loss='sparse_categorical_crossentropy',
                  metrics=['accuracy'])
    return model

nn_model = build_nn(X_train.shape[1], len(np.unique(y)))
nn_model.fit(X_train, y_train, epochs=EPOCHS, verbose=0)

# Modelo de Árvore de Decisão
tree_model = DecisionTreeClassifier(random_state=RANDOM_STATE)
tree_model.fit(X_train, y_train)

# Avaliação dos modelos
def evaluate_model(model, X_test, y_test, is_nn=False):
    if is_nn:
        preds = model.predict(X_test)
        preds_classes = preds.argmax(axis=1)
        mse = mean_squared_error(y_test, preds_classes)
        loss, accuracy = model.evaluate(X_test, y_test, verbose=0)
    else:
        preds_classes = model.predict(X_test)
        preds_probs = model.predict_proba(X_test)
        mse = mean_squared_error(y_test, preds_classes)
        loss = log_loss(y_test, preds_probs)
        accuracy = accuracy_score(y_test, preds_classes)

    return loss, accuracy, mse

nn_loss, nn_accuracy, nn_mse = evaluate_model(nn_model, X_test, y_test, is_nn=True)
tree_loss, tree_accuracy, tree_mse = evaluate_model(tree_model, X_test, y_test, is_nn=False)

# Comparação
results = {
    "Neural Network": {"Loss": nn_loss, "Accuracy": nn_accuracy, "MSE": nn_mse},
    "Decision Tree": {"Loss": tree_loss, "Accuracy": tree_accuracy, "MSE": tree_mse}
}

# Exibição de resultados
for model, metrics in results.items():
    print(f"{model} - Loss: {metrics['Loss']:.4f}, Accuracy: {metrics['Accuracy']:.4f}, MSE: {metrics['MSE']:.4f}")

# Visualização
plt.figure(figsize=(10, 6))
plt.bar(results.keys(), [results[m]["MSE"] for m in results], color=['blue', 'orange'])
plt.title("Comparação do MSE entre Modelos")
plt.ylabel("MSE")
plt.show()

"""Questão 7 - De acordo com o tipo de problema que seu dado representa (classificação ou regressão), indique:

Questão 7.1 - Qual o tipos de métrica mais adequada para avaliar este modelo (dentre as estudadas)?

Matriz de confusão.

Questão 7.2 - Tomando como base a métrica utilizada para avaliar seu modelo, discuta o resultado que ela apresentou. Compare os valores de performance que seu modelo encontrou com o valor de pesquisas que usam o mesmo dataset (aplicado a outros algoritmos) e discuta as diferenças existentes quanto a performance destes.

Como visto acima, o modelo apresentou alta perfomance. Similar a minha análise, outros usuários no Kaggle (site provedor do dataset), também obtiveram resultados similares, aonde mais da metade dos usuários apresentam uso elevado dos aparelhos eletrônicos.

Pesquise qual o parâmetro utilizado para criar um novo modelo para seu problema com a profundidade reduzida em 50% do original. Após isso, reavalie este novo modelo e explique o motivo que levou a diferença de performance (caso exista)

Aparentemente, o modelo utilizado pelo usuário Noey, do Kaggle, utiliziou diversas representações e gráficos para representar as classes, atributos e suas correlações, visto que este mesmo usuário representou diferentes formar de exemplificar o dataset, eu acredito que ele estava com ferramentas mais adequadas em mãos. Vale acresentar que ele usou muitas boxplots.
"""